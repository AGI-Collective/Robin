[2023-11-09 02:34:41,663] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:46,534] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-11-09 02:34:46,534] [INFO] [runner.py:555:main] cmd = /pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/envs/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed ./scripts/zero3.json --model_name_or_path /pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b --version v1 --data_path /pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/datasets/playground/data/llava_v1_5_mix665k.json --image_folder /pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/datasets/playground/data --vision_tower /pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip --pretrain_mm_mlp_adapter /pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir ./checkpoints/llava-v1.5-7b-lora --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 100 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb --finetune_ve True
[2023-11-09 02:34:48,671] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.16.2-1+cuda11.8
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.16.2-1
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.16.2-1
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 NCCL_LIB_DIR=/lib
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 HOROVOD_NCCL_HOME=
[2023-11-09 02:34:52,559] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.16.2-1+cuda11.8
[2023-11-09 02:34:52,560] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2023-11-09 02:34:52,560] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.16.2-1
[2023-11-09 02:34:52,560] [INFO] [launch.py:138:main] 0 HOROVOD_NCCL_LINK=
[2023-11-09 02:34:52,560] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5]}
[2023-11-09 02:34:52,560] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=6, node_rank=0
[2023-11-09 02:34:52,560] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5]})
[2023-11-09 02:34:52,560] [INFO] [launch.py:163:main] dist_world_size=6
[2023-11-09 02:34:52,560] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5
[2023-11-09 02:34:58,925] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:58,925] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:58,925] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:58,925] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:58,925] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:34:58,925] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-11-09 02:35:00,586] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-09 02:35:00,586] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-09 02:35:00,586] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-09 02:35:00,586] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-09 02:35:00,587] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-09 02:35:00,587] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-09 02:35:00,587] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-09 02:35:00,587] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-11-09 02:35:00,587] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-09 02:35:00,587] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-09 02:35:00,587] [INFO] [comm.py:594:init_distributed] cdb=None
[2023-11-09 02:35:00,587] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-11-09 02:35:00,587] [INFO] [comm.py:594:init_distributed] cdb=None
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
[2023-11-09 02:35:03,581] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 6.74B parameters
Adding LoRA adapters...
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
ModelArguments(model_name_or_path='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', version='v1', freeze_backbone=False, tune_mm_mlp_adapter=False, vision_tower='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', mm_vision_select_layer=-2, pretrain_mm_mlp_adapter='/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', mm_projector_type='mlp2x_gelu', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_vision_select_feature='patch')
[2023-11-09 02:36:10,403] [WARNING] [partition_parameters.py:836:_post_init_method] param `class_embedding` in CLIPVisionEmbeddings not on GPU so was not broadcasted from rank 0
[2023-11-09 02:36:10,688] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 7.04B parameters
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlavaLlamaForCausalLM(
      (model): LlavaLlamaModel(
        (embed_tokens): Embedding(32000, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (v_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (up_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (down_proj): Linear(
                in_features=11008, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act_fn): SiLUActivation()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
        (vision_tower): CLIPVisionTower(
          (vision_tower): CLIPVisionModel(
            (vision_model): CLIPVisionTransformer(
              (embeddings): CLIPVisionEmbeddings(
                (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
                (position_embedding): Embedding(577, 1024)
              )
              (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (encoder): CLIPEncoder(
                (layers): ModuleList(
                  (0-23): 24 x CLIPEncoderLayer(
                    (self_attn): CLIPAttention(
                      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (mlp): CLIPMLP(
                      (activation_fn): QuickGELUActivation()
                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                    )
                    (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  )
                )
              )
              (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (mm_projector): Sequential(
          (0): Linear(in_features=1024, out_features=4096, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=4096, out_features=4096, bias=True)
        )
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.self_attn.q_proj.weight False
base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.weight False
base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.weight False
base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.weight False
base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.self_attn.q_proj.weight False
base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.weight False
base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.weight False
base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.weight False
base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.self_attn.q_proj.weight False
base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.weight False
base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.weight False
base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.weight False
base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.self_attn.q_proj.weight False
base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.weight False
base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.weight False
base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.weight False
base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.self_attn.q_proj.weight False
base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.weight False
base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.weight False
base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.weight False
base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.self_attn.q_proj.weight False
base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.weight False
base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.weight False
base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.weight False
base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.class_embedding False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias False
Formatting inputs...Skip in lazy modebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight
 False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.bias False
base_model.model.model.mm_projector.0.weight True
base_model.model.model.mm_projector.0.bias True
base_model.model.model.mm_projector.2.weight True
base_model.model.model.mm_projector.2.bias True
base_model.model.lm_head.weight False
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlavaLlamaForCausalLM(
      (model): LlavaLlamaModel(
        (embed_tokens): Embedding(32000, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (v_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (up_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (down_proj): Linear(
                in_features=11008, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act_fn): SiLUActivation()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
        (vision_tower): CLIPVisionTower(
          (vision_tower): CLIPVisionModel(
            (vision_model): CLIPVisionTransformer(
              (embeddings): CLIPVisionEmbeddings(
                (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
                (position_embedding): Embedding(577, 1024)
              )
              (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (encoder): CLIPEncoder(
                (layers): ModuleList(
                  (0-23): 24 x CLIPEncoderLayer(
                    (self_attn): CLIPAttention(
                      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (mlp): CLIPMLP(
                      (activation_fn): QuickGELUActivation()
                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                    )
                    (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  )
                )
              )
              (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (mm_projector): Sequential(
          (0): Linear(in_features=1024, out_features=4096, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=4096, out_features=4096, bias=True)
        )
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.self_attn.q_proj.weight False
base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.weight False
base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.weight False
base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.weight False
base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.self_attn.q_proj.weight False
base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.weight False
base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.weight False
base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.weight False
base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.self_attn.q_proj.weight False
base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.weight False
base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.weight False
base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.weight False
base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.self_attn.q_proj.weight False
base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.weight False
base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.weight False
base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.weight False
base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.self_attn.q_proj.weight False
base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.weight False
base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.weight False
base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.weight False
base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.self_attn.q_proj.weight False
base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.weight False
base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.weight False
base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.weight False
base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.class_embedding False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.bias False
base_model.model.model.mm_projector.0.weight True
base_model.model.model.mm_projector.0.bias True
base_model.model.model.mm_projector.2.weight True
base_model.model.model.mm_projector.2.bias True
base_model.model.lm_head.weight False
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlavaLlamaForCausalLM(
      (model): LlavaLlamaModel(
        (embed_tokens): Embedding(32000, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (v_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (up_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (down_proj): Linear(
                in_features=11008, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act_fn): SiLUActivation()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
        (vision_tower): CLIPVisionTower(
          (vision_tower): CLIPVisionModel(
            (vision_model): CLIPVisionTransformer(
              (embeddings): CLIPVisionEmbeddings(
                (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
                (position_embedding): Embedding(577, 1024)
              )
              (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (encoder): CLIPEncoder(
                (layers): ModuleList(
                  (0-23): 24 x CLIPEncoderLayer(
                    (self_attn): CLIPAttention(
                      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (mlp): CLIPMLP(
                      (activation_fn): QuickGELUActivation()
                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                    )
                    (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  )
                )
              )
              (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (mm_projector): Sequential(
          (0): Linear(in_features=1024, out_features=4096, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=4096, out_features=4096, bias=True)
        )
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.self_attn.q_proj.weight False
base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.weight False
base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.weight False
base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.weight False
base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.self_attn.q_proj.weight False
base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.weight False
base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.weight False
base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.weight False
base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.self_attn.q_proj.weight False
base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.weight False
base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.weight False
base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.weight False
base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.self_attn.q_proj.weight False
base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.weight False
base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.weight False
base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.weight False
base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.self_attn.q_proj.weight False
base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.weight False
base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.weight False
base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.weight False
base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.self_attn.q_proj.weight False
base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.weight False
base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.weight False
base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.weight False
base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.class_embedding False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.bias False
base_model.model.model.mm_projector.0.weight True
base_model.model.model.mm_projector.0.bias True
base_model.model.model.mm_projector.2.weight True
base_model.model.model.mm_projector.2.bias True
base_model.model.lm_head.weight False
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlavaLlamaForCausalLM(
      (model): LlavaLlamaModel(
        (embed_tokens): Embedding(32000, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (v_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (up_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (down_proj): Linear(
                in_features=11008, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act_fn): SiLUActivation()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
        (vision_tower): CLIPVisionTower(
          (vision_tower): CLIPVisionModel(
            (vision_model): CLIPVisionTransformer(
              (embeddings): CLIPVisionEmbeddings(
                (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
                (position_embedding): Embedding(577, 1024)
              )
              (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (encoder): CLIPEncoder(
                (layers): ModuleList(
                  (0-23): 24 x CLIPEncoderLayer(
                    (self_attn): CLIPAttention(
                      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (mlp): CLIPMLP(
                      (activation_fn): QuickGELUActivation()
                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                    )
                    (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  )
                )
              )
              (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (mm_projector): Sequential(
          (0): Linear(in_features=1024, out_features=4096, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=4096, out_features=4096, bias=True)
        )
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.self_attn.q_proj.weight False
base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.weight False
base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.weight False
base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.weight False
base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.self_attn.q_proj.weight False
base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.weight False
base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.weight False
base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.weight False
base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.self_attn.q_proj.weight False
base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.weight False
base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.weight False
base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.weight False
base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.self_attn.q_proj.weight False
base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.weight False
base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.weight False
base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.weight False
base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.self_attn.q_proj.weight False
base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.weight False
base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.weight False
base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.weight False
base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.self_attn.q_proj.weight False
base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.weight False
base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.weight False
base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.weight False
base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.class_embedding False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.biasPeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlavaLlamaForCausalLM(
      (model): LlavaLlamaModel(
        (embed_tokens): Embedding(32000, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (v_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (up_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (down_proj): Linear(
                in_features=11008, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act_fn): SiLUActivation()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
        (vision_tower): CLIPVisionTower(
          (vision_tower): CLIPVisionModel(
            (vision_model): CLIPVisionTransformer(
              (embeddings): CLIPVisionEmbeddings(
                (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
                (position_embedding): Embedding(577, 1024)
              )
              (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (encoder): CLIPEncoder(
                (layers): ModuleList(
                  (0-23): 24 x CLIPEncoderLayer(
                    (self_attn): CLIPAttention(
                      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (mlp): CLIPMLP(
                      (activation_fn): QuickGELUActivation()
                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                    )
                    (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  )
                )
              )
              (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (mm_projector): Sequential(
          (0): Linear(in_features=1024, out_features=4096, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=4096, out_features=4096, bias=True)
        )
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
) 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weightbase_model.model.model.embed_tokens.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias False
base_model.model.model.layers.0.self_attn.q_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight Falsebase_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.biasTrue 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weightbase_model.model.model.layers.0.self_attn.k_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias False
base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight
 False
base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weightbase_model.model.model.layers.0.self_attn.v_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weightTrue 
False
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias  TrueFalse

base_model.model.model.layers.0.self_attn.o_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias
 False
base_model.model.model.layers.0.mlp.gate_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.biasbase_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias
 False
base_model.model.model.layers.0.mlp.up_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.biasbase_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weightbase_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias Falsebase_model.model.model.layers.0.mlp.down_proj.weight
 Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight
 False
base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias  TrueFalse

base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias base_model.model.model.layers.0.input_layernorm.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight base_model.model.model.layers.0.post_attention_layernorm.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias
 False
base_model.model.model.layers.1.self_attn.q_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.biasbase_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weightbase_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias Falsebase_model.model.model.layers.1.self_attn.k_proj.weight
 Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight
 False
base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias  TrueFalse

base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.biasbase_model.model.model.layers.1.self_attn.v_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weightbase_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight Falsebase_model.model.model.layers.1.self_attn.o_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.biasFalse 
False
base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.biasbase_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight Falsebase_model.model.model.layers.1.mlp.gate_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.biasFalse 
False
base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.biasbase_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weightbase_model.model.model.layers.1.mlp.up_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias Falsebase_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight
 Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight
 Falsebase_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.biasTrue 
False
base_model.model.model.layers.1.mlp.down_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias
 False
base_model.model.model.layers.1.input_layernorm.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weightFalse 
False
base_model.model.model.layers.1.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weightbase_model.model.model.layers.2.self_attn.q_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weightTrue 
False
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias  TrueFalse

base_model.model.model.layers.2.self_attn.k_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.biasbase_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weightbase_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias Falsebase_model.model.model.layers.2.self_attn.v_proj.weight
 Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight
 False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias  TrueFalse

base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.biasbase_model.model.model.layers.2.self_attn.o_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias
 Falsebase_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight
 Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight
 False
base_model.model.model.layers.2.mlp.gate_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weightbase_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight Falsebase_model.model.model.layers.2.mlp.up_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.biasFalse 
False
base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.biasbase_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weightbase_model.model.model.layers.2.mlp.down_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias Falsebase_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight
 Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight
 Falsebase_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.biasTrue 
False
base_model.model.model.layers.2.input_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight  FalseFalse

base_model.model.model.layers.2.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias  FalseFalse

base_model.model.model.layers.3.self_attn.q_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.biasbase_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias
 False
base_model.model.model.layers.3.self_attn.k_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.biasbase_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias
 False
base_model.model.model.layers.3.self_attn.v_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias
 False
base_model.model.model.layers.3.self_attn.o_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.biasbase_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias
 False
base_model.model.model.layers.3.mlp.gate_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.biasbase_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias
 False
base_model.model.model.layers.3.mlp.up_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.biasbase_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias
 False
base_model.model.model.layers.3.mlp.down_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.biasbase_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weightbase_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias Falsebase_model.model.model.layers.3.input_layernorm.weight
 Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight
 Falsebase_model.model.model.layers.3.post_attention_layernorm.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.biasFalse 
False
base_model.model.model.layers.4.self_attn.q_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias
 False
base_model.model.model.layers.4.self_attn.k_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.biasbase_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias
 False
base_model.model.model.layers.4.self_attn.v_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias
 False
base_model.model.model.layers.4.self_attn.o_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight
 False
base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias  TrueFalse

base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias Falsebase_model.model.model.layers.4.mlp.gate_proj.weight
 Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight
 False
base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias  TrueFalse

base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weightTrue 
False
base_model.model.model.layers.4.mlp.up_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weightbase_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight Falsebase_model.model.model.layers.4.mlp.down_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.biasFalse 
False
base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.biasbase_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight Falsebase_model.model.model.layers.4.input_layernorm.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.biasFalse 
False
base_model.model.model.layers.4.post_attention_layernorm.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight
 False
base_model.model.model.layers.5.self_attn.q_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weightbase_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight Falsebase_model.model.model.layers.5.self_attn.k_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.biasFalse 
False
base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weightTrue 
False
base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weightbase_model.model.model.layers.5.self_attn.v_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias Falsebase_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight
 Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight
 Falsebase_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.biasTrue 
False
base_model.model.model.layers.5.self_attn.o_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.biasbase_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weightbase_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias False
base_model.model.model.layers.5.mlp.gate_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight
 False
base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias  TrueFalse

base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.biasbase_model.model.model.layers.5.mlp.up_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight Falsebase_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.biasTrue 
False
base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight
 False
base_model.model.model.layers.5.mlp.down_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weightbase_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight Falsebase_model.model.model.layers.5.input_layernorm.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.biasFalse 
False
base_model.model.model.layers.5.post_attention_layernorm.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weightFalse 
False
base_model.model.model.layers.6.self_attn.q_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weightbase_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight base_model.model.model.layers.6.self_attn.k_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias
 False
base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weightTrue 
False
base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias  TrueFalse

base_model.model.model.layers.6.self_attn.v_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias
 False
base_model.model.model.layers.6.self_attn.o_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.biasbase_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias
 False
base_model.model.model.layers.6.mlp.gate_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias
 False
base_model.model.model.layers.6.mlp.up_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight
 False
base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias  TrueFalse

base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.biasbase_model.model.model.layers.6.mlp.down_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight Falsebase_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.biasTrue 
False
base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight
 False
base_model.model.model.layers.6.input_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias  FalseFalse

base_model.model.model.layers.6.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.biasbase_model.model.model.layers.7.self_attn.q_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight Falsebase_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.biasTrue 
False
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weightTrue 
False
base_model.model.model.layers.7.self_attn.k_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weightbase_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight base_model.model.model.layers.7.self_attn.v_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias
 False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weightTrue 
False
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weightbase_model.model.model.layers.7.self_attn.o_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias Falsebase_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight
 True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias
 False
base_model.model.model.layers.7.mlp.gate_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias
 False
base_model.model.model.layers.7.mlp.up_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.biasbase_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias
 False
base_model.model.model.layers.7.mlp.down_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight
 False
base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias  TrueFalse

base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias base_model.model.model.layers.7.input_layernorm.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight base_model.model.model.layers.7.post_attention_layernorm.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias
 False
base_model.model.model.layers.8.self_attn.q_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight
 False
base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias  TrueFalse

base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.biasbase_model.model.model.layers.8.self_attn.k_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight Falsebase_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.biasTrue 
False
base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weightTrue 
False
base_model.model.model.layers.8.self_attn.v_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weightbase_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight base_model.model.model.layers.8.self_attn.o_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias
 False
base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.biasbase_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight Falsebase_model.model.model.layers.8.mlp.gate_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.biasFalse 
False
base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.biasbase_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight base_model.model.model.layers.8.mlp.up_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias
 False
base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weightTrue 
False
base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias  TrueFalse

base_model.model.model.layers.8.mlp.down_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.biasbase_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias
 False
base_model.model.model.layers.8.input_layernorm.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight
 Falsebase_model.model.model.layers.8.post_attention_layernorm.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.biasFalse 
False
base_model.model.model.layers.9.self_attn.q_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.biasbase_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias
 False
base_model.model.model.layers.9.self_attn.k_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight
 False
base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias  TrueFalse

base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.biasbase_model.model.model.layers.9.self_attn.v_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight Falsebase_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.biasTrue 
False
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weightTrue 
False
base_model.model.model.layers.9.self_attn.o_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weightbase_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight Falsebase_model.model.model.layers.9.mlp.gate_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.biasFalse 
False
base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.biasbase_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight base_model.model.model.layers.9.mlp.up_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias
 False
base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight
 Falsebase_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.biasTrue 
False
base_model.model.model.layers.9.mlp.down_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.biasbase_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias
 False
base_model.model.model.layers.9.input_layernorm.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weightFalse 
False
base_model.model.model.layers.9.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weightbase_model.model.model.layers.10.self_attn.q_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias Falsebase_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight
 True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias
 False
base_model.model.model.layers.10.self_attn.k_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.biasbase_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias
 False
base_model.model.model.layers.10.self_attn.v_proj.weight Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight
 False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias  TrueFalse

base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.biasbase_model.model.model.layers.10.self_attn.o_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight Falsebase_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.biasTrue 
False
base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weightTrue 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.biasbase_model.model.model.layers.10.mlp.gate_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias
 Falsebase_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight
 True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight Falsebase_model.model.model.layers.10.mlp.up_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.biasFalse 
False
base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.biasbase_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight base_model.model.model.layers.10.mlp.down_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias
 False
base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight
 Falsebase_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.biasTrue 
False
base_model.model.model.layers.10.input_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight  FalseFalse

base_model.model.model.layers.10.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias  FalseFalse

base_model.model.model.layers.11.self_attn.q_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias
 False
base_model.model.model.layers.11.self_attn.k_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.biasbase_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weightbase_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias Falsebase_model.model.model.layers.11.self_attn.v_proj.weight
 Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight
 False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias  TrueFalse

base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.biasbase_model.model.model.layers.11.self_attn.o_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias
 Falsebase_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight
 Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight
 False
base_model.model.model.layers.11.mlp.gate_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weightbase_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight Falsebase_model.model.model.layers.11.mlp.up_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.biasFalse 
False
base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.biasbase_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weightbase_model.model.model.layers.11.mlp.down_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias Falsebase_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight
 Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight
 Falsebase_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.biasTrue 
False
base_model.model.model.layers.11.input_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight  FalseFalse

base_model.model.model.layers.11.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias  FalseFalse

base_model.model.model.layers.12.self_attn.q_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.biasbase_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias
 False
base_model.model.model.layers.12.self_attn.k_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.biasbase_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias
 False
base_model.model.model.layers.12.self_attn.v_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.biasbase_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weightbase_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias base_model.model.model.layers.12.self_attn.o_proj.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight Falsebase_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.biasTrue 
False
base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weightTrue 
False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.biasbase_model.model.model.layers.12.mlp.gate_proj.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weightbase_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight Falsebase_model.model.model.layers.12.mlp.up_proj.weight
 base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.biasFalse 
False
base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight  TrueFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.biasbase_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight  FalseTrue

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight base_model.model.model.layers.12.mlp.down_proj.weightFalse 
Falsebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias
 False
base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weightTrue 
False
base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias  TrueFalse

base_model.model.model.layers.12.input_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight  FalseFalse

base_model.model.model.layers.12.post_attention_layernorm.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias  FalseFalse

base_model.model.model.layers.13.self_attn.q_proj.weightbase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight  FalseFalse

base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weightFalse 
True
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weightFalse 
Truebase_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias
 False
base_model.model.model.layers.13.self_attn.k_proj.weight base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.weightFalse 
False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.biasbase_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight  FalseTrue

base_model.model.model.mm_projector.0.weightbase_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight  TrueTrue

base_model.model.model.mm_projector.0.bias True
base_model.model.model.layers.13.self_attn.v_proj.weight base_model.model.model.mm_projector.2.weightFalse 
True
base_model.model.model.mm_projector.2.biasbase_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight  TrueTrue

base_model.model.lm_head.weight base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weightFalse 
True
base_model.model.model.layers.13.self_attn.o_proj.weight False
base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.self_attn.q_proj.weight False
base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.weight False
base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.weight False
base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.weight False
base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.self_attn.q_proj.weight False
base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.weight False
base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.weight False
base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.weight False
base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.self_attn.q_proj.weight False
base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.weight False
base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.weight False
base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.weight False
base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.class_embedding False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.bias False
base_model.model.model.mm_projector.0.weight True
base_model.model.model.mm_projector.0.bias True
base_model.model.model.mm_projector.2.weight True
base_model.model.model.mm_projector.2.bias True
base_model.model.lm_head.weight False
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlavaLlamaForCausalLM(
      (model): LlavaLlamaModel(
        (embed_tokens): Embedding(32000, 4096, padding_idx=0)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (v_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (up_proj): Linear(
                in_features=4096, out_features=11008, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (down_proj): Linear(
                in_features=11008, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=128, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=128, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act_fn): SiLUActivation()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
        (vision_tower): CLIPVisionTower(
          (vision_tower): CLIPVisionModel(
            (vision_model): CLIPVisionTransformer(
              (embeddings): CLIPVisionEmbeddings(
                (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
                (position_embedding): Embedding(577, 1024)
              )
              (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (encoder): CLIPEncoder(
                (layers): ModuleList(
                  (0-23): 24 x CLIPEncoderLayer(
                    (self_attn): CLIPAttention(
                      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    )
                    (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (mlp): CLIPMLP(
                      (activation_fn): QuickGELUActivation()
                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                    )
                    (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  )
                )
              )
              (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (mm_projector): Sequential(
          (0): Linear(in_features=1024, out_features=4096, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=4096, out_features=4096, bias=True)
        )
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.self_attn.q_proj.weight False
base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.weight False
base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.weight False
base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.weight False
base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.self_attn.q_proj.weight False
base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.weight False
base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.weight False
base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.weight False
base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.self_attn.q_proj.weight False
base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.weight False
base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.weight False
base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.weight False
base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.self_attn.q_proj.weight False
base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.weight False
base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.weight False
base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.weight False
base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.self_attn.q_proj.weight False
base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.weight False
base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.weight False
base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.weight False
base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.self_attn.q_proj.weight False
base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.weight False
base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.weight False
base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.weight False
base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight True
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight True
base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight True
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.class_embedding False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.weight False
base_model.model.model.vision_tower.vision_tower.vision_model.post_layernorm.bias False
base_model.model.model.mm_projector.0.weight True
base_model.model.model.mm_projector.0.bias True
base_model.model.model.mm_projector.2.weight True
base_model.model.model.mm_projector.2.bias True
base_model.model.lm_head.weight False
Parameter Offload: Total persistent parameters: 599040 in 312 params
{'loss': 1.306, 'learning_rate': 9.615384615384617e-07, 'epoch': 0.0}
{'loss': 1.3646, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.0}
{'loss': 1.4089, 'learning_rate': 2.884615384615385e-06, 'epoch': 0.0}
{'loss': 1.3164, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.0}
{'loss': 1.3958, 'learning_rate': 4.807692307692308e-06, 'epoch': 0.0}
{'loss': 1.2865, 'learning_rate': 5.76923076923077e-06, 'epoch': 0.0}
{'loss': 1.3464, 'learning_rate': 6.730769230769231e-06, 'epoch': 0.0}
{'loss': 1.3607, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.0}
{'loss': 1.3477, 'learning_rate': 8.653846153846155e-06, 'epoch': 0.0}
{'loss': 1.2591, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.0}
{'loss': 1.2565, 'learning_rate': 1.0576923076923077e-05, 'epoch': 0.0}
{'loss': 1.2188, 'learning_rate': 1.153846153846154e-05, 'epoch': 0.0}
{'loss': 1.151, 'learning_rate': 1.25e-05, 'epoch': 0.0}
{'loss': 1.2148, 'learning_rate': 1.3461538461538462e-05, 'epoch': 0.0}
{'loss': 1.1458, 'learning_rate': 1.4423076923076923e-05, 'epoch': 0.0}
[2023-11-09 02:39:31,612] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.1693, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.0}
{'loss': 1.2083, 'learning_rate': 1.6346153846153847e-05, 'epoch': 0.0}
{'loss': 1.1706, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.0}
{'loss': 1.1523, 'learning_rate': 1.826923076923077e-05, 'epoch': 0.0}
{'loss': 1.1484, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.0}
{'loss': 1.1302, 'learning_rate': 2.0192307692307694e-05, 'epoch': 0.0}
{'loss': 1.2135, 'learning_rate': 2.1153846153846154e-05, 'epoch': 0.0}
{'loss': 1.138, 'learning_rate': 2.2115384615384616e-05, 'epoch': 0.0}
[2023-11-09 02:40:57,581] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.1016, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.0}
{'loss': 1.1836, 'learning_rate': 2.4038461538461542e-05, 'epoch': 0.0}
{'loss': 1.0853, 'learning_rate': 2.5e-05, 'epoch': 0.0}
[2023-11-09 02:41:31,553] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.2713, 'learning_rate': 2.5961538461538464e-05, 'epoch': 0.0}
{'loss': 1.1211, 'learning_rate': 2.6923076923076923e-05, 'epoch': 0.0}
{'loss': 1.0807, 'learning_rate': 2.7884615384615386e-05, 'epoch': 0.0}
{'loss': 1.0742, 'learning_rate': 2.8846153846153845e-05, 'epoch': 0.0}
{'loss': 1.0469, 'learning_rate': 2.9807692307692308e-05, 'epoch': 0.0}
{'loss': 0.3255, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.0}
{'loss': 1.0462, 'learning_rate': 3.1730769230769234e-05, 'epoch': 0.0}
{'loss': 1.028, 'learning_rate': 3.269230769230769e-05, 'epoch': 0.0}
{'loss': 1.0521, 'learning_rate': 3.365384615384616e-05, 'epoch': 0.01}
{'loss': 1.1237, 'learning_rate': 3.461538461538462e-05, 'epoch': 0.01}
{'loss': 1.0365, 'learning_rate': 3.557692307692308e-05, 'epoch': 0.01}
{'loss': 1.069, 'learning_rate': 3.653846153846154e-05, 'epoch': 0.01}
{'loss': 1.11, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.01}
{'loss': 0.9824, 'learning_rate': 3.846153846153846e-05, 'epoch': 0.01}
{'loss': 1.0, 'learning_rate': 3.942307692307692e-05, 'epoch': 0.01}
{'loss': 1.0768, 'learning_rate': 4.038461538461539e-05, 'epoch': 0.01}
{'loss': 1.0684, 'learning_rate': 4.134615384615385e-05, 'epoch': 0.01}
{'loss': 1.0046, 'learning_rate': 4.230769230769231e-05, 'epoch': 0.01}
[2023-11-09 02:44:47,148] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.0234, 'learning_rate': 4.326923076923077e-05, 'epoch': 0.01}
{'loss': 1.0176, 'learning_rate': 4.423076923076923e-05, 'epoch': 0.01}
{'loss': 0.9941, 'learning_rate': 4.519230769230769e-05, 'epoch': 0.01}
{'loss': 1.0286, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.01}
{'loss': 1.0273, 'learning_rate': 4.711538461538462e-05, 'epoch': 0.01}
{'loss': 1.0586, 'learning_rate': 4.8076923076923084e-05, 'epoch': 0.01}
{'loss': 0.9694, 'learning_rate': 4.9038461538461536e-05, 'epoch': 0.01}
{'loss': 0.9896, 'learning_rate': 5e-05, 'epoch': 0.01}
{'loss': 1.0326, 'learning_rate': 5.096153846153846e-05, 'epoch': 0.01}
{'loss': 0.9889, 'learning_rate': 5.192307692307693e-05, 'epoch': 0.01}
{'loss': 1.0104, 'learning_rate': 5.288461538461539e-05, 'epoch': 0.01}
{'loss': 1.0228, 'learning_rate': 5.384615384615385e-05, 'epoch': 0.01}
{'loss': 1.0469, 'learning_rate': 5.480769230769231e-05, 'epoch': 0.01}
{'loss': 1.0729, 'learning_rate': 5.576923076923077e-05, 'epoch': 0.01}
{'loss': 0.9987, 'learning_rate': 5.673076923076923e-05, 'epoch': 0.01}
{'loss': 0.3022, 'learning_rate': 5.769230769230769e-05, 'epoch': 0.01}
{'loss': 1.0091, 'learning_rate': 5.865384615384616e-05, 'epoch': 0.01}
{'loss': 0.9089, 'learning_rate': 5.9615384615384616e-05, 'epoch': 0.01}
{'loss': 1.0098, 'learning_rate': 6.0576923076923076e-05, 'epoch': 0.01}
{'loss': 0.9648, 'learning_rate': 6.153846153846155e-05, 'epoch': 0.01}
{'loss': 1.0312, 'learning_rate': 6.25e-05, 'epoch': 0.01}
{'loss': 0.9785, 'learning_rate': 6.346153846153847e-05, 'epoch': 0.01}
{'loss': 0.9668, 'learning_rate': 6.442307692307693e-05, 'epoch': 0.01}
{'loss': 0.9674, 'learning_rate': 6.538461538461539e-05, 'epoch': 0.01}
{'loss': 0.9935, 'learning_rate': 6.634615384615385e-05, 'epoch': 0.01}
{'loss': 0.9844, 'learning_rate': 6.730769230769232e-05, 'epoch': 0.01}
{'loss': 0.9688, 'learning_rate': 6.826923076923077e-05, 'epoch': 0.01}
{'loss': 1.0059, 'learning_rate': 6.923076923076924e-05, 'epoch': 0.01}
{'loss': 0.9779, 'learning_rate': 7.019230769230769e-05, 'epoch': 0.01}
{'loss': 0.9408, 'learning_rate': 7.115384615384616e-05, 'epoch': 0.01}
{'loss': 1.0026, 'learning_rate': 7.211538461538462e-05, 'epoch': 0.01}
{'loss': 1.043, 'learning_rate': 7.307692307692307e-05, 'epoch': 0.01}
{'loss': 1.0299, 'learning_rate': 7.403846153846154e-05, 'epoch': 0.01}
{'loss': 0.9518, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.01}
{'loss': 0.9551, 'learning_rate': 7.596153846153846e-05, 'epoch': 0.01}
{'loss': 0.972, 'learning_rate': 7.692307692307693e-05, 'epoch': 0.01}
{'loss': 1.0117, 'learning_rate': 7.788461538461539e-05, 'epoch': 0.01}
{'loss': 1.0234, 'learning_rate': 7.884615384615384e-05, 'epoch': 0.01}
{'loss': 0.9629, 'learning_rate': 7.980769230769231e-05, 'epoch': 0.01}
{'loss': 0.9297, 'learning_rate': 8.076923076923078e-05, 'epoch': 0.01}
{'loss': 0.9688, 'learning_rate': 8.173076923076923e-05, 'epoch': 0.01}
{'loss': 0.9421, 'learning_rate': 8.26923076923077e-05, 'epoch': 0.01}
{'loss': 0.9818, 'learning_rate': 8.365384615384616e-05, 'epoch': 0.01}
{'loss': 0.9987, 'learning_rate': 8.461538461538461e-05, 'epoch': 0.01}
{'loss': 1.0026, 'learning_rate': 8.557692307692308e-05, 'epoch': 0.01}
{'loss': 1.056, 'learning_rate': 8.653846153846155e-05, 'epoch': 0.01}
{'loss': 1.0319, 'learning_rate': 8.75e-05, 'epoch': 0.01}
{'loss': 1.0234, 'learning_rate': 8.846153846153847e-05, 'epoch': 0.01}
{'loss': 0.9355, 'learning_rate': 8.942307692307693e-05, 'epoch': 0.01}
{'loss': 0.9551, 'learning_rate': 9.038461538461538e-05, 'epoch': 0.01}
{'loss': 0.9635, 'learning_rate': 9.134615384615385e-05, 'epoch': 0.01}
{'loss': 1.0365, 'learning_rate': 9.230769230769232e-05, 'epoch': 0.01}
{'loss': 1.0234, 'learning_rate': 9.326923076923077e-05, 'epoch': 0.01}
{'loss': 1.0267, 'learning_rate': 9.423076923076924e-05, 'epoch': 0.01}
{'loss': 0.9427, 'learning_rate': 9.519230769230769e-05, 'epoch': 0.01}
{'loss': 0.9479, 'learning_rate': 9.615384615384617e-05, 'epoch': 0.01}
{'loss': 0.9316, 'learning_rate': 9.711538461538462e-05, 'epoch': 0.01}
{'loss': 0.9655, 'learning_rate': 9.807692307692307e-05, 'epoch': 0.01}
{'loss': 0.9935, 'learning_rate': 9.903846153846155e-05, 'epoch': 0.01}
{'loss': 0.9844, 'learning_rate': 0.0001, 'epoch': 0.02}
{'loss': 0.3057, 'learning_rate': 0.00010096153846153846, 'epoch': 0.02}
{'loss': 1.0195, 'learning_rate': 0.00010192307692307692, 'epoch': 0.02}
{'loss': 1.0456, 'learning_rate': 0.00010288461538461538, 'epoch': 0.02}
{'loss': 0.8646, 'learning_rate': 0.00010384615384615386, 'epoch': 0.02}
{'loss': 0.9948, 'learning_rate': 0.00010480769230769232, 'epoch': 0.02}
{'loss': 0.2718, 'learning_rate': 0.00010576923076923077, 'epoch': 0.02}
{'loss': 0.9577, 'learning_rate': 0.00010673076923076924, 'epoch': 0.02}
{'loss': 0.9362, 'learning_rate': 0.0001076923076923077, 'epoch': 0.02}
{'loss': 0.9772, 'learning_rate': 0.00010865384615384615, 'epoch': 0.02}
{'loss': 0.985, 'learning_rate': 0.00010961538461538463, 'epoch': 0.02}
{'loss': 0.9473, 'learning_rate': 0.00011057692307692309, 'epoch': 0.02}
{'loss': 0.2881, 'learning_rate': 0.00011153846153846154, 'epoch': 0.02}
{'loss': 1.0098, 'learning_rate': 0.00011250000000000001, 'epoch': 0.02}
{'loss': 1.0065, 'learning_rate': 0.00011346153846153846, 'epoch': 0.02}
{'loss': 0.903, 'learning_rate': 0.00011442307692307692, 'epoch': 0.02}
{'loss': 0.9434, 'learning_rate': 0.00011538461538461538, 'epoch': 0.02}
{'loss': 0.9727, 'learning_rate': 0.00011634615384615386, 'epoch': 0.02}
{'loss': 0.918, 'learning_rate': 0.00011730769230769231, 'epoch': 0.02}
{'loss': 0.3027, 'learning_rate': 0.00011826923076923078, 'epoch': 0.02}
{'loss': 0.9512, 'learning_rate': 0.00011923076923076923, 'epoch': 0.02}
{'loss': 0.9167, 'learning_rate': 0.0001201923076923077, 'epoch': 0.02}
{'loss': 0.9095, 'learning_rate': 0.00012115384615384615, 'epoch': 0.02}
{'loss': 0.9954, 'learning_rate': 0.00012211538461538463, 'epoch': 0.02}
{'loss': 1.0534, 'learning_rate': 0.0001230769230769231, 'epoch': 0.02}
{'loss': 0.9167, 'learning_rate': 0.00012403846153846154, 'epoch': 0.02}
{'loss': 0.9863, 'learning_rate': 0.000125, 'epoch': 0.02}
{'loss': 1.013, 'learning_rate': 0.00012596153846153847, 'epoch': 0.02}
{'loss': 0.9837, 'learning_rate': 0.00012692307692307693, 'epoch': 0.02}
{'loss': 0.9206, 'learning_rate': 0.00012788461538461537, 'epoch': 0.02}
{'loss': 0.9368, 'learning_rate': 0.00012884615384615387, 'epoch': 0.02}
{'loss': 0.9225, 'learning_rate': 0.0001298076923076923, 'epoch': 0.02}
{'loss': 0.2534, 'learning_rate': 0.00013076923076923077, 'epoch': 0.02}
{'loss': 0.9941, 'learning_rate': 0.00013173076923076924, 'epoch': 0.02}
{'loss': 0.959, 'learning_rate': 0.0001326923076923077, 'epoch': 0.02}
{'loss': 0.9681, 'learning_rate': 0.00013365384615384614, 'epoch': 0.02}
{'loss': 0.974, 'learning_rate': 0.00013461538461538464, 'epoch': 0.02}
{'loss': 0.9095, 'learning_rate': 0.0001355769230769231, 'epoch': 0.02}
{'loss': 0.9668, 'learning_rate': 0.00013653846153846154, 'epoch': 0.02}
{'loss': 0.9368, 'learning_rate': 0.0001375, 'epoch': 0.02}
{'loss': 1.0039, 'learning_rate': 0.00013846153846153847, 'epoch': 0.02}
{'loss': 0.9349, 'learning_rate': 0.0001394230769230769, 'epoch': 0.02}
{'loss': 0.9102, 'learning_rate': 0.00014038461538461538, 'epoch': 0.02}
{'loss': 0.998, 'learning_rate': 0.00014134615384615387, 'epoch': 0.02}
{'loss': 0.9655, 'learning_rate': 0.0001423076923076923, 'epoch': 0.02}
{'loss': 0.9629, 'learning_rate': 0.00014326923076923078, 'epoch': 0.02}
{'loss': 0.931, 'learning_rate': 0.00014423076923076924, 'epoch': 0.02}
{'loss': 0.9889, 'learning_rate': 0.00014519230769230768, 'epoch': 0.02}
{'loss': 0.9837, 'learning_rate': 0.00014615384615384615, 'epoch': 0.02}
{'loss': 0.9681, 'learning_rate': 0.00014711538461538464, 'epoch': 0.02}
{'loss': 0.9928, 'learning_rate': 0.00014807692307692308, 'epoch': 0.02}
{'loss': 0.9993, 'learning_rate': 0.00014903846153846155, 'epoch': 0.02}
{'loss': 0.9831, 'learning_rate': 0.00015000000000000001, 'epoch': 0.02}
{'loss': 0.9447, 'learning_rate': 0.00015096153846153845, 'epoch': 0.02}
{'loss': 0.2897, 'learning_rate': 0.00015192307692307692, 'epoch': 0.02}
{'loss': 0.957, 'learning_rate': 0.00015288461538461539, 'epoch': 0.02}
{'loss': 0.9779, 'learning_rate': 0.00015384615384615385, 'epoch': 0.02}
[2023-11-09 03:05:48,328] [WARNING] [stage3.py:1850:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9714, 'learning_rate': 0.00015480769230769232, 'epoch': 0.02}
[2023-11-09 03:06:03,404] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9316, 'learning_rate': 0.00015576923076923078, 'epoch': 0.02}
{'loss': 0.9967, 'learning_rate': 0.00015673076923076925, 'epoch': 0.02}
{'loss': 0.3294, 'learning_rate': 0.0001576923076923077, 'epoch': 0.02}
{'loss': 0.998, 'learning_rate': 0.00015865384615384616, 'epoch': 0.02}
{'loss': 0.9798, 'learning_rate': 0.00015961538461538462, 'epoch': 0.02}
{'loss': 0.9766, 'learning_rate': 0.0001605769230769231, 'epoch': 0.02}
{'loss': 0.9342, 'learning_rate': 0.00016153846153846155, 'epoch': 0.02}
{'loss': 0.9902, 'learning_rate': 0.00016250000000000002, 'epoch': 0.02}
{'loss': 0.8945, 'learning_rate': 0.00016346153846153846, 'epoch': 0.02}
{'loss': 0.9486, 'learning_rate': 0.00016442307692307692, 'epoch': 0.02}
{'loss': 0.9186, 'learning_rate': 0.0001653846153846154, 'epoch': 0.02}
{'loss': 0.9401, 'learning_rate': 0.00016634615384615386, 'epoch': 0.02}
{'loss': 0.9056, 'learning_rate': 0.00016730769230769232, 'epoch': 0.03}
{'loss': 0.9694, 'learning_rate': 0.0001682692307692308, 'epoch': 0.03}
{'loss': 0.987, 'learning_rate': 0.00016923076923076923, 'epoch': 0.03}
{'loss': 1.0273, 'learning_rate': 0.0001701923076923077, 'epoch': 0.03}
{'loss': 0.9674, 'learning_rate': 0.00017115384615384616, 'epoch': 0.03}
{'loss': 0.9551, 'learning_rate': 0.00017211538461538463, 'epoch': 0.03}
{'loss': 0.8926, 'learning_rate': 0.0001730769230769231, 'epoch': 0.03}
{'loss': 0.9329, 'learning_rate': 0.00017403846153846156, 'epoch': 0.03}
[2023-11-09 03:09:37,168] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9453, 'learning_rate': 0.000175, 'epoch': 0.03}
[2023-11-09 03:09:55,281] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.2575, 'learning_rate': 0.00017596153846153846, 'epoch': 0.03}
{'loss': 0.8783, 'learning_rate': 0.00017692307692307693, 'epoch': 0.03}
[2023-11-09 03:10:22,264] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9694, 'learning_rate': 0.00017788461538461537, 'epoch': 0.03}
{'loss': 0.9557, 'learning_rate': 0.00017884615384615386, 'epoch': 0.03}
{'loss': 0.944, 'learning_rate': 0.00017980769230769233, 'epoch': 0.03}
{'loss': 0.8991, 'learning_rate': 0.00018076923076923077, 'epoch': 0.03}
{'loss': 0.9108, 'learning_rate': 0.00018173076923076923, 'epoch': 0.03}
{'loss': 0.3071, 'learning_rate': 0.0001826923076923077, 'epoch': 0.03}
{'loss': 0.9681, 'learning_rate': 0.00018365384615384617, 'epoch': 0.03}
{'loss': 1.0345, 'learning_rate': 0.00018461538461538463, 'epoch': 0.03}
{'loss': 0.2712, 'learning_rate': 0.0001855769230769231, 'epoch': 0.03}
{'loss': 0.2965, 'learning_rate': 0.00018653846153846154, 'epoch': 0.03}
{'loss': 0.9661, 'learning_rate': 0.0001875, 'epoch': 0.03}
{'loss': 0.9401, 'learning_rate': 0.00018846153846153847, 'epoch': 0.03}
{'loss': 0.9232, 'learning_rate': 0.00018942307692307694, 'epoch': 0.03}
{'loss': 1.0, 'learning_rate': 0.00019038461538461538, 'epoch': 0.03}
{'loss': 0.8919, 'learning_rate': 0.00019134615384615387, 'epoch': 0.03}
{'loss': 0.3076, 'learning_rate': 0.00019230769230769233, 'epoch': 0.03}
{'loss': 0.9889, 'learning_rate': 0.00019326923076923077, 'epoch': 0.03}
{'loss': 0.9271, 'learning_rate': 0.00019423076923076924, 'epoch': 0.03}
{'loss': 0.929, 'learning_rate': 0.0001951923076923077, 'epoch': 0.03}
{'loss': 0.2928, 'learning_rate': 0.00019615384615384615, 'epoch': 0.03}
{'loss': 0.9505, 'learning_rate': 0.00019711538461538464, 'epoch': 0.03}
{'loss': 0.9564, 'learning_rate': 0.0001980769230769231, 'epoch': 0.03}
{'loss': 0.9421, 'learning_rate': 0.00019903846153846154, 'epoch': 0.03}
{'loss': 1.0033, 'learning_rate': 0.0002, 'epoch': 0.03}
{'loss': 0.9753, 'learning_rate': 0.0001999999890819892, 'epoch': 0.03}
{'loss': 0.9277, 'learning_rate': 0.00019999995632795923, 'epoch': 0.03}
{'loss': 0.9941, 'learning_rate': 0.00019999990173791719, 'epoch': 0.03}
{'loss': 0.3149, 'learning_rate': 0.000199999825311875, 'epoch': 0.03}
{'loss': 0.946, 'learning_rate': 0.00019999972704984938, 'epoch': 0.03}
{'loss': 0.9876, 'learning_rate': 0.00019999960695186178, 'epoch': 0.03}
{'loss': 0.931, 'learning_rate': 0.0001999994650179384, 'epoch': 0.03}
{'loss': 0.9258, 'learning_rate': 0.00019999930124811027, 'epoch': 0.03}
{'loss': 0.9264, 'learning_rate': 0.00019999911564241312, 'epoch': 0.03}
{'loss': 0.9499, 'learning_rate': 0.00019999890820088752, 'epoch': 0.03}
{'loss': 0.9857, 'learning_rate': 0.0001999986789235787, 'epoch': 0.03}
{'loss': 0.9935, 'learning_rate': 0.00019999842781053676, 'epoch': 0.03}
{'loss': 0.9701, 'learning_rate': 0.0001999981548618166, 'epoch': 0.03}
{'loss': 0.9186, 'learning_rate': 0.0001999978600774777, 'epoch': 0.03}
{'loss': 0.9694, 'learning_rate': 0.0001999975434575845, 'epoch': 0.03}
{'loss': 1.0033, 'learning_rate': 0.00019999720500220615, 'epoch': 0.03}
{'loss': 0.9271, 'learning_rate': 0.00019999684471141648, 'epoch': 0.03}
{'loss': 0.9538, 'learning_rate': 0.00019999646258529424, 'epoch': 0.03}
{'loss': 1.0, 'learning_rate': 0.00019999605862392286, 'epoch': 0.03}
{'loss': 0.9642, 'learning_rate': 0.00019999563282739052, 'epoch': 0.03}
{'loss': 0.9792, 'learning_rate': 0.0001999951851957902, 'epoch': 0.03}
{'loss': 0.9655, 'learning_rate': 0.00019999471572921965, 'epoch': 0.03}
{'loss': 0.8997, 'learning_rate': 0.0001999942244277814, 'epoch': 0.03}
{'loss': 0.9583, 'learning_rate': 0.00019999371129158272, 'epoch': 0.03}
{'loss': 1.0072, 'learning_rate': 0.00019999317632073563, 'epoch': 0.03}
{'loss': 0.9036, 'learning_rate': 0.00019999261951535703, 'epoch': 0.03}
{'loss': 0.9062, 'learning_rate': 0.0001999920408755684, 'epoch': 0.03}
{'loss': 0.3079, 'learning_rate': 0.00019999144040149614, 'epoch': 0.03}
{'loss': 0.9212, 'learning_rate': 0.0001999908180932714, 'epoch': 0.03}
{'loss': 0.9284, 'learning_rate': 0.00019999017395103, 'epoch': 0.03}
{'loss': 0.9342, 'learning_rate': 0.00019998950797491265, 'epoch': 0.03}
[2023-11-09 03:20:45,378] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.9883, 'learning_rate': 0.00019998882016506475, 'epoch': 0.03}
[2023-11-09 03:21:02,076] [WARNING] [stage3.py:1850:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3486, 'learning_rate': 0.00019998811052163648, 'epoch': 0.03}
{'loss': 0.9648, 'learning_rate': 0.00019998737904478283, 'epoch': 0.03}
{'loss': 0.9141, 'learning_rate': 0.00019998662573466353, 'epoch': 0.04}
{'loss': 0.8672, 'learning_rate': 0.000199985850591443, 'epoch': 0.04}
{'loss': 0.9824, 'learning_rate': 0.00019998505361529058, 'epoch': 0.04}
[2023-11-09 03:21:56,445] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2620
[2023-11-09 03:21:56,445] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2621
[2023-11-09 03:21:57,890] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2622
[2023-11-09 03:21:59,971] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2623
[2023-11-09 03:22:02,128] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2624
[2023-11-09 03:22:03,527] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2625
[2023-11-09 03:22:05,338] [ERROR] [launch.py:321:sigkill_handler] ['/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/envs/bin/python', '-u', 'llava/train/train_mem.py', '--local_rank=5', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/vicuna-7b', '--version', 'v1', '--data_path', '/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/datasets/playground/data/llava_v1_5_mix665k.json', '--image_folder', '/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/datasets/playground/data', '--vision_tower', '/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/hf/clip', '--pretrain_mm_mlp_adapter', '/pfss/mlde/workspaces/mlde_wsp_Ramstedt_Mila/daniel/robin_llava/checkpoints/llava-v1.5-7b-pretrain/checkpoint-300/mm_projector.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/llava-v1.5-7b-lora', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '100', '--save_total_limit', '1', '--learning_rate', '2e-4', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--finetune_ve', 'True'] exits with return code = 1
